{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d58fcb",
   "metadata": {},
   "source": [
    "# Problem 7: Allometric scaling and pharmacokinetics\n",
    "\n",
    "The study of pharmacokinetics in medicine seeks the ability to determine the clearance rate $C$ at which a human body removes a drug. \n",
    "This is valuable for determining the proper drug to administer a patient, and is particularly crucial for pediatric medicine where there are large ranges of body mass $M$. \n",
    "\n",
    "Over decades (and indeed [centuries](https://en.wikipedia.org/wiki/Square%E2%80%93cube_law)) of empirical and theory-driven studies, researchers have determined that power-laws can fit this data,\n",
    "\n",
    "$ C = k M^\\alpha $\n",
    "\n",
    "where $k$ and $\\alpha$ are parameters that depend on the drug.\n",
    "The value of $\\alpha$ has mechanistic meaning, and is typically $\\alpha \\in (0.6,1.0)$, but many clinical settings use $\\alpha=0.75$.\n",
    "See [Calvier et al, \"Allometric Scaling of Clearance in Paediatric Patients\" Clinical Pharmacokinetics 2017](https://link.springer.com/article/10.1007/s40262-016-0436-x) and [Valkengoed et al., \"All You Need to Know About Allometric Scaling: An Integrative Review on the Theoretical Basis, Empirical Evidence, and Application in Human Pharmacology\", Clinical Pharmakokinetics 2025](https://link.springer.com/article/10.1007/s40262-024-01444-6).\n",
    "\n",
    "The following generates a synthetic dataset of size $N_{\\textrm{obs}}$ for $C$ and $M$, assuming a ground truth of $\\alpha_{\\textrm{GT}}$ and normal random noise with $\\sigma$.\n",
    "\n",
    "Note that the patients sample has uniform random masses. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e853df40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T19:41:59.338191Z",
     "iopub.status.busy": "2025-04-05T19:41:59.335830Z",
     "iopub.status.idle": "2025-04-05T19:41:59.536995Z",
     "shell.execute_reply": "2025-04-05T19:41:59.536434Z"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "# set.seed(123)\n",
    "\n",
    "# Define parameters\n",
    "Nobs <- 50\n",
    "M_min <- 12  # minimum body mass in kg\n",
    "M_max <- 100 # maximum body mass in kg\n",
    "alpha_gt <- 0.68\n",
    "C_min <- 500  # minimum clearance rate in mL/min\n",
    "C_max <- 1500 # maximum clearance rate in mL/min\n",
    "sigma <- 100  # standard deviation for the noise (adjust as needed)\n",
    "\n",
    "# Generate body mass values (uniform distribution)\n",
    "M <- runif(Nobs, min = M_min, max = M_max)\n",
    "\n",
    "# Calculate the value of k that will scale clearance rates to the desired range\n",
    "max_M_alpha <- max(M)^alpha_gt\n",
    "k_gt <- C_max / max_M_alpha\n",
    "\n",
    "# Calculate theoretical clearance rates\n",
    "C_theoretical <- k_gt * M^alpha_gt\n",
    "\n",
    "# Add noise to the clearance rates\n",
    "noise <- rnorm(Nobs, mean = 0, sd = sigma)\n",
    "C_observed <- C_theoretical + noise\n",
    "\n",
    "# Create a data frame\n",
    "patient_data <- data.frame(\n",
    "  PatientID = 1:Nobs,\n",
    "  BodyMass = M,\n",
    "  ClearanceRate_Theoretical = C_theoretical,\n",
    "  ClearanceRate_Observed = C_observed\n",
    ")\n",
    "\n",
    "# Print summary statistics\n",
    "# summary(patient_data)\n",
    "\n",
    "# Plot the data\n",
    "plot(patient_data$BodyMass, patient_data$ClearanceRate_Observed,\n",
    "     xlab = \"Body Mass (kg)\",\n",
    "     ylab = \"Drug Clearance Rate (mL/min)\",\n",
    "     main = \"Relationship Between Body Mass and Drug Clearance Rate\",\n",
    "     pch = 19,\n",
    "     col = \"blue\")\n",
    "\n",
    "# # Add a smooth curve of the theoretical relationship\n",
    "# curve(k * x^alpha, from = M_min, to = M_max, add = TRUE, col = \"red\", lwd = 2)\n",
    "\n",
    "# Add a legend\n",
    "legend(\"bottomright\", \n",
    "       legend = c(\"Synthetic Data\"),\n",
    "       col = c(\"blue\"),\n",
    "       pch = c(19, NA),\n",
    "       lty = c(NA, 1),\n",
    "       lwd = c(NA, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b920de",
   "metadata": {},
   "source": [
    "## Question i\n",
    "\n",
    "Transform the equation by taking the log. \n",
    "Your new equation should be a relationship between $lC = log(x)$ and $log(M)$, and be linear function of $k_1$ and $\\alpha$. \n",
    "\n",
    "Take the log of the data.\n",
    "Write code to perform linear regression to estimate $\\alpha$.\n",
    "Call this $\\tilde{\\alpha}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe08b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T19:41:59.552229Z",
     "iopub.status.busy": "2025-04-05T19:41:59.539468Z",
     "iopub.status.idle": "2025-04-05T19:41:59.563672Z",
     "shell.execute_reply": "2025-04-05T19:41:59.563077Z"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Take logs of the data\n",
    "log_M <- log(M)\n",
    "log_C <- log(C_observed)\n",
    "\n",
    "# Perform linear regression on the log-transformed data\n",
    "log_model <- lm(log_C ~ log_M)\n",
    "alpha_estimated <- coef(log_model)[2]  # Slope corresponds to alpha\n",
    "\n",
    "# Print results\n",
    "cat(\"Ground truth alpha:\", alpha_gt, \"\\n\")\n",
    "cat(\"Estimated alpha from log-linear regression:\", alpha_estimated, \"\\n\")\n",
    "cat(\"Absolute error:\", abs(alpha_estimated - alpha_gt), \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f57a41",
   "metadata": {},
   "source": [
    "Perform a sweep where you vary $\\sigma$ and generate a new synthetic dataset.\n",
    "For each $\\sigma$, compute $|\\tilde{\\alpha} - \\alpha_{\\textrm{GT}}|$, the true error.\n",
    "Plot the true error versus $\\sigma$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ea13b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T19:41:59.565599Z",
     "iopub.status.busy": "2025-04-05T19:41:59.565143Z",
     "iopub.status.idle": "2025-04-05T19:41:59.775265Z",
     "shell.execute_reply": "2025-04-05T19:41:59.774683Z"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Perform sweep over different noise levels\n",
    "sigma_values <- seq(1, 100, by = 1)\n",
    "error_values_log <- numeric(length(sigma_values))\n",
    "\n",
    "for (i in 1:length(sigma_values)) {\n",
    "  current_sigma <- sigma_values[i]\n",
    "  \n",
    "  # Generate new noise and observed clearance\n",
    "  noise <- rnorm(Nobs, mean = 0, sd = current_sigma)\n",
    "  C_observed <- C_theoretical + noise\n",
    "  \n",
    "  # Some noise values might make C_observed negative, which would make log undefined\n",
    "  # Handle this by using only positive values\n",
    "  valid_indices <- C_observed > 0\n",
    "  \n",
    "  if (sum(valid_indices) < 0.9 * Nobs) {\n",
    "    # If too many negative values, skip this sigma\n",
    "    error_values_log[i] <- NA\n",
    "    next\n",
    "  }\n",
    "  \n",
    "  # Take logs of valid data\n",
    "  log_M_valid <- log_M[valid_indices]\n",
    "  log_C_valid <- log(C_observed[valid_indices])\n",
    "  \n",
    "  # Fit log-linear model\n",
    "  log_model <- lm(log_C_valid ~ log_M_valid)\n",
    "  alpha_estimated <- coef(log_model)[2]\n",
    "  \n",
    "  # Calculate error\n",
    "  error_values_log[i] <- abs(alpha_estimated - alpha_gt)\n",
    "}\n",
    "\n",
    "# Plot error vs sigma\n",
    "plot(sigma_values, error_values_log, \n",
    "     type = \"p\", \n",
    "     xlab = \"Noise Level (sigma)\", \n",
    "     ylab = \"Absolute Error in Alpha Estimate\",\n",
    "     main = \"Error in Log-Linear Regression vs. Noise Level\",\n",
    "     pch = 19,\n",
    "     col = \"blue\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92af716",
   "metadata": {},
   "source": [
    "## Question ii\n",
    "Now, let's perform a nonlinear fit using R's built-in `nls` function.\n",
    "Do not transform the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0038a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T19:41:59.778331Z",
     "iopub.status.busy": "2025-04-05T19:41:59.777869Z",
     "iopub.status.idle": "2025-04-05T19:41:59.789799Z",
     "shell.execute_reply": "2025-04-05T19:41:59.789223Z"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create data frame for nls\n",
    "data <- data.frame(M = M, C = C_observed)\n",
    "\n",
    "# Fit nonlinear model\n",
    "# Start with reasonable initial values for parameters\n",
    "nls_model <- nls(C ~ k * M^alpha, data = data, \n",
    "                start = list(k = 100, alpha = 0.7))\n",
    "\n",
    "# Get estimated parameters\n",
    "params <- coef(nls_model)\n",
    "k_estimated <- params[\"k\"]\n",
    "alpha_estimated <- params[\"alpha\"]\n",
    "\n",
    "# Print results\n",
    "cat(\"True alpha:\", alpha_gt, \"\\n\")\n",
    "cat(\"Estimated alpha from nonlinear regression:\", alpha_estimated, \"\\n\")\n",
    "cat(\"Absolute error:\", abs(alpha_estimated - alpha_gt), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8ad93b",
   "metadata": {},
   "source": [
    "Perform the same sweep as above, but now with `nls`. \n",
    "Make the same plot of $|\\tilde{\\alpha} - \\alpha_{\\textrm{GT}}|$, the true error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dabfbcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T19:41:59.791723Z",
     "iopub.status.busy": "2025-04-05T19:41:59.791291Z",
     "iopub.status.idle": "2025-04-05T19:42:00.106462Z",
     "shell.execute_reply": "2025-04-05T19:42:00.105905Z"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c20d349",
   "metadata": {},
   "source": [
    "We expect the true error to be smaller. Is it? By how much? For all values of $N_{\\textrm{obs}}$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f8726",
   "metadata": {},
   "source": [
    "## Question iii\n",
    "\n",
    "In the above, the synthetic data was provided for a sample of patients with uniformly-distributed masses. \n",
    "\n",
    "Informal question:\n",
    "What is the most realisitic distribution of masses for a patient sample? \n",
    "For adult data? For pediatrics (children)?\n",
    "\n",
    "Formal question:\n",
    "Implement another distribution of patient masses, and repeat both log-transformed linear fit and non-linear fit.\n",
    "\n",
    "* What distribution gives the largest discrepancy between the two methods? \n",
    "* What distribution gives the smallest discrepancy between the two methods?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd8a4b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T19:42:00.109944Z",
     "iopub.status.busy": "2025-04-05T19:42:00.109493Z",
     "iopub.status.idle": "2025-04-05T19:42:00.113590Z",
     "shell.execute_reply": "2025-04-05T19:42:00.113063Z"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "r_env"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
